# MNIST/CIFAR-10_-Analysis_Using_CNN
Designing and optimizing neural networks for best performance for MNIST and CIFAR datasets
The goal of these written codes and analysis was to design these networks and optimize them to their best performance by choosing the right hyperparameters for each network, such as the learning rate, batch size and the choice of optimizer (‘SGD’, ‘adam’, ‘RMSProp’) for the models and calculate based on the relevant accuracy parameters. \
Also, added in the `<CNN_Notebook.ipynb>` are the explanations on the models and the potential reasons why the models performed well or underperformed based on the parameters set for the networks.
